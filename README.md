# End-To-End-Data-Engineering-ETL-Pipeline-Project-Azure-Databricks-Spark-UnityCatalog

## *Project Overview:*
This project demonstrates the design, development, & implementation of a robust, scalable & fully automated end-to-end data engineering ETL pipeline built on **Microsoft Azure and Databricks**. The pipeline processes raw data (parquet files), transforms it through a **Medallion Architecture (Bronze, Silver & Gold Layers)**, and prepares it for analytical consumption, which can ultimately connect to Power BI for business reporting.

## *Key Technologies Used:*

#### *1. Azure Data Lake Storage Gen2 (ADLS Gen2):* 
This serves as the scalable & secure foundation for our data lakehouse. Its hierarchical namespace and cost-effective storage were crucial for housing all data layers (raw, processed, & curated), and handling large volumes of diverse data. 
