{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea3acd0d-b848-49bd-af09-f30818b04241",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **DATA PIPELINE**\n",
    "### **Streaming Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8605b884-12c9-44b5-98d6-a645f3b1c17b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected internal error when monkey patching dlt module: cannot import name 'overrides' from partially initialized module 'dlt' (most likely due to a circular import) (/local_disk0/.ephemeral_nfs/envs/pythonEnv-c2adf2ab-14ea-4c25-bb7d-663c13c629a5/lib/python3.11/site-packages/dlt/__init__.py)\n"
     ]
    }
   ],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cfc69e4-9a3e-4296-ac71-80cd205de4d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Creating expectations (rules) to follow for pipeline\n",
    "rules = {\n",
    "    \"rule1\" : \"product_id IS NOT NULL\",\n",
    "    \"rule2\" : \"product_name IS NOT NULL\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db63293c-f3e0-4388-b542-d44ba52a75aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mException\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-7736680522580365>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[38;5;129m@dlt\u001B[39m\u001B[38;5;241m.\u001B[39mtable()\n",
       "\u001B[1;32m      2\u001B[0m \n",
       "\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mDimProducts_stage\u001B[39m():\n",
       "\u001B[1;32m      4\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m spark\u001B[38;5;241m.\u001B[39mreadStream\u001B[38;5;241m.\u001B[39mtable(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatabricks_etl_catalog.silver.products_silver\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-c2adf2ab-14ea-4c25-bb7d-663c13c629a5/lib/python3.11/site-packages/dlt/api.py:97\u001B[0m, in \u001B[0;36mtable\u001B[0;34m(query_function, name, comment, spark_conf, table_properties, partition_cols, path, schema, temporary, cluster_by, row_filter)\u001B[0m\n",
       "\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtable\u001B[39m(\n",
       "\u001B[1;32m     58\u001B[0m     query_function: Optional[Callable[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, DataFrame]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n",
       "\u001B[1;32m     59\u001B[0m     name: Optional[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m     68\u001B[0m     row_filter: Optional[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n",
       "\u001B[1;32m     69\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Callable[[Callable[[], DataFrame]], Callable[[], DataFrame]]:\n",
       "\u001B[1;32m     70\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m     71\u001B[0m \u001B[38;5;124;03m    (Return a) decorator to define a table in the pipeline and mark a function as the table's query\u001B[39;00m\n",
       "\u001B[1;32m     72\u001B[0m \u001B[38;5;124;03m    function.\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m     95\u001B[0m \u001B[38;5;124;03m    :param row_filter: A row filter SQL clause that filters the rows in the table.\u001B[39;00m\n",
       "\u001B[1;32m     96\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m---> 97\u001B[0m     __local_execution_disabled()\n",
       "\u001B[1;32m     98\u001B[0m     \u001B[38;5;66;03m# For a pipeline that looks like this,\u001B[39;00m\n",
       "\u001B[1;32m     99\u001B[0m     \u001B[38;5;66;03m# @create_table(name=\"tbl\")\u001B[39;00m\n",
       "\u001B[1;32m    100\u001B[0m     \u001B[38;5;66;03m# def query_fn():\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    107\u001B[0m     \u001B[38;5;66;03m# Python will call create_table(query_fn), so we must call outer and pass query_fn to make it\u001B[39;00m\n",
       "\u001B[1;32m    108\u001B[0m     \u001B[38;5;66;03m# behave the same as the case where the user does specify args.\u001B[39;00m\n",
       "\u001B[1;32m    109\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m query_function \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-c2adf2ab-14ea-4c25-bb7d-663c13c629a5/lib/python3.11/site-packages/dlt/api.py:31\u001B[0m, in \u001B[0;36m__local_execution_disabled\u001B[0;34m()\u001B[0m\n",
       "\u001B[1;32m     29\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(error_msg)\n",
       "\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m---> 31\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(error_msg)\n",
       "\n",
       "\u001B[0;31mException\u001B[0m: This is a stub that only contains the interfaces to Delta Live Tables. Delta Live Tables pipelines cannot be run locally. To learn more,  see https://docs.databricks.com/en/delta-live-tables/develop-locally.html. If you would like to run your code for testing purposes, you can switch this error message off by calling enable_local_execution() before running your pipeline code."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "Exception",
        "evalue": "This is a stub that only contains the interfaces to Delta Live Tables. Delta Live Tables pipelines cannot be run locally. To learn more,  see https://docs.databricks.com/en/delta-live-tables/develop-locally.html. If you would like to run your code for testing purposes, you can switch this error message off by calling enable_local_execution() before running your pipeline code."
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>Exception</span>: This is a stub that only contains the interfaces to Delta Live Tables. Delta Live Tables pipelines cannot be run locally. To learn more,  see https://docs.databricks.com/en/delta-live-tables/develop-locally.html. If you would like to run your code for testing purposes, you can switch this error message off by calling enable_local_execution() before running your pipeline code."
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mException\u001B[0m                                 Traceback (most recent call last)",
        "File \u001B[0;32m<command-7736680522580365>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;129m@dlt\u001B[39m\u001B[38;5;241m.\u001B[39mtable()\n\u001B[1;32m      2\u001B[0m \n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mDimProducts_stage\u001B[39m():\n\u001B[1;32m      4\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m spark\u001B[38;5;241m.\u001B[39mreadStream\u001B[38;5;241m.\u001B[39mtable(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdatabricks_etl_catalog.silver.products_silver\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-c2adf2ab-14ea-4c25-bb7d-663c13c629a5/lib/python3.11/site-packages/dlt/api.py:97\u001B[0m, in \u001B[0;36mtable\u001B[0;34m(query_function, name, comment, spark_conf, table_properties, partition_cols, path, schema, temporary, cluster_by, row_filter)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtable\u001B[39m(\n\u001B[1;32m     58\u001B[0m     query_function: Optional[Callable[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, DataFrame]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     59\u001B[0m     name: Optional[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     68\u001B[0m     row_filter: Optional[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     69\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Callable[[Callable[[], DataFrame]], Callable[[], DataFrame]]:\n\u001B[1;32m     70\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;124;03m    (Return a) decorator to define a table in the pipeline and mark a function as the table's query\u001B[39;00m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;124;03m    function.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;124;03m    :param row_filter: A row filter SQL clause that filters the rows in the table.\u001B[39;00m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 97\u001B[0m     __local_execution_disabled()\n\u001B[1;32m     98\u001B[0m     \u001B[38;5;66;03m# For a pipeline that looks like this,\u001B[39;00m\n\u001B[1;32m     99\u001B[0m     \u001B[38;5;66;03m# @create_table(name=\"tbl\")\u001B[39;00m\n\u001B[1;32m    100\u001B[0m     \u001B[38;5;66;03m# def query_fn():\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    107\u001B[0m     \u001B[38;5;66;03m# Python will call create_table(query_fn), so we must call outer and pass query_fn to make it\u001B[39;00m\n\u001B[1;32m    108\u001B[0m     \u001B[38;5;66;03m# behave the same as the case where the user does specify args.\u001B[39;00m\n\u001B[1;32m    109\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m query_function \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-c2adf2ab-14ea-4c25-bb7d-663c13c629a5/lib/python3.11/site-packages/dlt/api.py:31\u001B[0m, in \u001B[0;36m__local_execution_disabled\u001B[0;34m()\u001B[0m\n\u001B[1;32m     29\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(error_msg)\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 31\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(error_msg)\n",
        "\u001B[0;31mException\u001B[0m: This is a stub that only contains the interfaces to Delta Live Tables. Delta Live Tables pipelines cannot be run locally. To learn more,  see https://docs.databricks.com/en/delta-live-tables/develop-locally.html. If you would like to run your code for testing purposes, you can switch this error message off by calling enable_local_execution() before running your pipeline code."
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "@dlt.table()\n",
    "\n",
    "@dlt.expect_all_or_drop(rules)\n",
    "\n",
    "def DimProducts_stage():\n",
    "  return (spark.readStream\n",
    "          .option(\"skipChangeCommits\", \"true\")  # Skip overwrite commits\n",
    "          .table(\"databricks_etl_catalog.silver.products_silver\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56deb460-12a9-4850-9871-fc8c9c094923",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Streaming View**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42b21bb1-2663-4621-a0cd-d2d4c11f7e45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-6097784868435295>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdlt\u001B[39;00m\u001B[38;5;66;03m# Creating empty streaming table\u001B[39;00m\n",
       "\u001B[1;32m      3\u001B[0m dlt\u001B[38;5;241m.\u001B[39mcreate_streaming_table(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDimProducts\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/autoreload/discoverability/hook.py:71\u001B[0m, in \u001B[0;36mAutoreloadDiscoverabilityHook._patched_import\u001B[0;34m(self, name, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_hint \u001B[38;5;129;01mand\u001B[39;00m (\n",
       "\u001B[1;32m     66\u001B[0m     (module \u001B[38;5;241m:=\u001B[39m sys\u001B[38;5;241m.\u001B[39mmodules\u001B[38;5;241m.\u001B[39mget(absolute_name)) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n",
       "\u001B[1;32m     67\u001B[0m     (fname \u001B[38;5;241m:=\u001B[39m get_allowed_file_name_or_none(module)) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n",
       "\u001B[1;32m     68\u001B[0m     (mtime \u001B[38;5;241m:=\u001B[39m os\u001B[38;5;241m.\u001B[39mstat(fname)\u001B[38;5;241m.\u001B[39mst_mtime) \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlast_mtime_by_modname\u001B[38;5;241m.\u001B[39mget(\n",
       "\u001B[1;32m     69\u001B[0m         absolute_name, \u001B[38;5;28mfloat\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minf\u001B[39m\u001B[38;5;124m\"\u001B[39m)) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_hint):\n",
       "\u001B[1;32m     70\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_hint \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\u001B[0;32m---> 71\u001B[0m module \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_builtins_import(name, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (fname \u001B[38;5;241m:=\u001B[39m fname \u001B[38;5;129;01mor\u001B[39;00m get_allowed_file_name_or_none(module)) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[1;32m     73\u001B[0m     mtime \u001B[38;5;241m=\u001B[39m mtime \u001B[38;5;129;01mor\u001B[39;00m os\u001B[38;5;241m.\u001B[39mstat(fname)\u001B[38;5;241m.\u001B[39mst_mtime\n",
       "\n",
       "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'dlt'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "ModuleNotFoundError",
        "evalue": "No module named 'dlt'"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>ModuleNotFoundError</span>: No module named 'dlt'"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
        "File \u001B[0;32m<command-6097784868435295>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mdlt\u001B[39;00m\u001B[38;5;66;03m# Creating empty streaming table\u001B[39;00m\n\u001B[1;32m      3\u001B[0m dlt\u001B[38;5;241m.\u001B[39mcreate_streaming_table(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDimProducts\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/autoreload/discoverability/hook.py:71\u001B[0m, in \u001B[0;36mAutoreloadDiscoverabilityHook._patched_import\u001B[0;34m(self, name, *args, **kwargs)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_hint \u001B[38;5;129;01mand\u001B[39;00m (\n\u001B[1;32m     66\u001B[0m     (module \u001B[38;5;241m:=\u001B[39m sys\u001B[38;5;241m.\u001B[39mmodules\u001B[38;5;241m.\u001B[39mget(absolute_name)) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m     67\u001B[0m     (fname \u001B[38;5;241m:=\u001B[39m get_allowed_file_name_or_none(module)) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m\n\u001B[1;32m     68\u001B[0m     (mtime \u001B[38;5;241m:=\u001B[39m os\u001B[38;5;241m.\u001B[39mstat(fname)\u001B[38;5;241m.\u001B[39mst_mtime) \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlast_mtime_by_modname\u001B[38;5;241m.\u001B[39mget(\n\u001B[1;32m     69\u001B[0m         absolute_name, \u001B[38;5;28mfloat\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minf\u001B[39m\u001B[38;5;124m\"\u001B[39m)) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_hint):\n\u001B[1;32m     70\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_hint \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 71\u001B[0m module \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_builtins_import(name, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (fname \u001B[38;5;241m:=\u001B[39m fname \u001B[38;5;129;01mor\u001B[39;00m get_allowed_file_name_or_none(module)) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     73\u001B[0m     mtime \u001B[38;5;241m=\u001B[39m mtime \u001B[38;5;129;01mor\u001B[39;00m os\u001B[38;5;241m.\u001B[39mstat(fname)\u001B[38;5;241m.\u001B[39mst_mtime\n",
        "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'dlt'"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dlt\n",
    "# Creating empty streaming table\n",
    "\n",
    "dlt.create_streaming_table(\"DimProducts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f900bf82-c92b-418d-8cbc-485e44dd224a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.view()\n",
    "\n",
    "def DimProducts_view():\n",
    "    df = spark.readStream.table(\"Live.DimProducts_stage\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0eeb1fe9-721b-4572-b3ad-56734484e6c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **DimProducts as SCD Type 2 with the help of DLT** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3455e56-b30a-46da-80b7-c7b049cb2721",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dlt.apply_changes(\n",
    "    target = \"DimProducts\",\n",
    "    source = \"Live.DimProducts_view\",\n",
    "    keys = [\"product_id\"],\n",
    "    sequence_by = \"product_id\",\n",
    "    stored_as_scd_type = 2\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Gold_Products",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}